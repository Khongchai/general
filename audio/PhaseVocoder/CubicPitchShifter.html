<!-- Interpolation-based phase vocoder -->

<!-- POC area before working on the real-time version -->

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Document</title>
  </head>
  <body>
    <div className="container">
      <label>Speed</label>
      <p id="current-rate"></p>
      <button data-playing="false" role="switch" aria-checked="false">
        <span>Play/Pause</span>
      </button>
      <button id="load-button">
        <span onclick="load()">Load</span>
      </button>
    </div>
    <canvas width="500" height="500" id="oscilloscope"></canvas>
  </body>
  <script>
    // Function to create a new stretched buffer
    /**
     * @param {AudioBuffer} audioBuffer
     * @param {number} rate
     */
    function shiftPitch(audioBuffer, rate) {
      const numChannels = audioBuffer.numberOfChannels;
      const oldLength = audioBuffer.length;
      const newLength = Math.floor(oldLength / rate);
      const newAudioBuffer = new AudioBuffer({
        length: newLength,
        sampleRate: audioBuffer.sampleRate,
        numberOfChannels: numChannels,
      });

      const maybeData = (float32Array, index) => {
        return float32Array[index] ?? 0;
      };

      // Loop through each channel
      for (let channel = 0; channel < numChannels; channel++) {
        const oldChannelData = audioBuffer.getChannelData(channel);
        const newChannelData = newAudioBuffer.getChannelData(channel);

        // Fill the stretched buffer
        let rateAcc = 0;
        for (
          let i = 2, rateAcc = rate * 2;
          i < newLength - 2;
          i++, rateAcc += rate
        ) {
          const interpolationPart = rateAcc;
          const sampleIndex = Math.floor(interpolationPart) + 1;
          const a = maybeData(oldChannelData, sampleIndex - 1);
          const b =
            (-11 * a) / 6 +
            3 * maybeData(oldChannelData, sampleIndex) -
            1.5 * maybeData(oldChannelData, sampleIndex + 1) +
            maybeData(oldChannelData, sampleIndex + 2) / 3;
          const c =
            a -
            2.5 * maybeData(oldChannelData, sampleIndex) +
            2 * maybeData(oldChannelData, sampleIndex + 1) -
            maybeData(oldChannelData, sampleIndex + 2) / 2;
          const d =
            -a / 6 +
            maybeData(oldChannelData, sampleIndex) / 2 -
            maybeData(oldChannelData, sampleIndex + 1) / 2 +
            maybeData(oldChannelData, sampleIndex + 2) / 6;
          const xInterpolation = interpolationPart - sampleIndex + 2;
          newChannelData[i] =
            a +
            b * xInterpolation +
            c * xInterpolation ** 2 +
            d * xInterpolation ** 3;
        }
      }

      return newAudioBuffer;
    }
  </script>
  <script>
    /** @type {Uint8Array} */
    let scratchBytes;
    async function main() {
      const audioContext = new AudioContext({
        sampleRate: 44_100,
      });

      const audioElement = document.querySelector("audio");
      const playButton = document.querySelector("button");
      let currentRate = 0.5;
      const rateElem = document.getElementById("current-rate");
      rateElem.innerHTML = String(currentRate);

      if (playButton === null || rateElem === null) {
        throw new Error("Some elements were not found");
      }

      /**
       * @type {ArrayBuffer}
       */
      const audioData = await fetch("../a.wav").then((response) =>
        response.arrayBuffer()
      );

      const uint8array = new Uint8Array(audioData);

      const oldBuffer = await audioContext.decodeAudioData(audioData);
      const audioBuffer = shiftPitch(oldBuffer, currentRate);

      const source = audioContext.createBufferSource();

      const analyzer = audioContext.createAnalyser();
      analyzer.fftSize = 2048;
      const bufferLength = analyzer.frequencyBinCount;
      scratchBytes = new Uint8Array(bufferLength);

      source.buffer = audioBuffer;
      source.connect(analyzer).connect(audioContext.destination);

      playButton.addEventListener("click", function () {
        if (this.dataset.playing === "false") {
          source.start(0);
          this.dataset.playing = "true";
        } else {
          source.stop(0);
          this.dataset.playing = "false";
        }
      });

      return analyzer;
    }

    let animationFrameId;
    function initCanvas(analyzer) {
      if (animationFrameId != null) cancelAnimationFrame();
      const canvas = document.getElementById("oscilloscope");
      const HEIGHT = 500;
      const WIDTH = 500;
      canvas.height = HEIGHT * devicePixelRatio;
      canvas.width = WIDTH * devicePixelRatio;
      const ctx = canvas.getContext("2d");

      function loop() {
        ctx.clearRect(0, 0, canvas.width, canvas.height);

        analyzer.getByteTimeDomainData(scratchBytes);

        ctx.fillStyle = "black";
        ctx.fillRect(0, 0, canvas.width, canvas.height);
        ctx.lineWidth = 2;
        ctx.strokeStyle = "white";
        ctx.beginPath();

        const bufferLength = scratchBytes.byteLength;
        const sliceWidth = canvas.width / bufferLength;
        let x = 0;

        for (let i = 0; i < bufferLength; i++) {
          const v = scratchBytes[i] / 128.0;
          const y = v * (canvas.height / 2);

          if (i === 0) {
            ctx.moveTo(x, y);
          } else {
            ctx.lineTo(x, y);
          }

          x += sliceWidth;
        }

        ctx.lineTo(canvas.width, canvas.height / 2);
        ctx.stroke();

        animationFrameId = requestAnimationFrame(loop);
      }

      loop();
    }

    /**
     * To force user interaction for audio context
     */
    async function load() {
      const analyzer = await main();
      initCanvas(analyzer);
      const loadButton = document.getElementById("load-button");
      if (!loadButton) {
        throw new Error("Load button could not be found");
      }

      loadButton.innerHTML = "Loaded";
    }
  </script>
</html>
